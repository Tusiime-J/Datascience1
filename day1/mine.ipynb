{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc76147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame head:\n",
      "   Duration         Date  Pulse  Maxpulse  Calories\n",
      "0        60  2023/10/01'  110.0     130.0     409.1\n",
      "1        60  2023/10/02'  117.0     145.0     479.0\n",
      "2        60  2023/10/03'  103.0     135.0     340.3\n",
      "3        45  2023/10/04'  109.0     175.0     282.4\n",
      "4        45  2023/10/05'  117.0     150.0     405.1\n",
      "\n",
      "Original DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31 entries, 0 to 30\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Duration  31 non-null     int64  \n",
      " 1   Date      29 non-null     object \n",
      " 2   Pulse     30 non-null     float64\n",
      " 3   Maxpulse  29 non-null     float64\n",
      " 4   Calories  27 non-null     float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n",
      "None\n",
      "\n",
      "Original DataFrame missing values before cleaning:\n",
      "Duration    0\n",
      "Date        2\n",
      "Pulse       1\n",
      "Maxpulse    2\n",
      "Calories    4\n",
      "dtype: int64\n",
      "\n",
      "Original DataFrame duplicates before cleaning:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Mine.csv\")\n",
    "# --- Initial Inspection of the DataFrame ---\n",
    "print(\"Original DataFrame head:\")\n",
    "print(df.head()) # Display the first 5 rows of the original DataFrame\n",
    "print(\"\\nOriginal DataFrame info:\")\n",
    "print(df.info()) # Display a summary of the DataFrame, including data types and non-null counts\n",
    "print(\"\\nOriginal DataFrame missing values before cleaning:\")\n",
    "print(df.isnull().sum()) # Count and display the number of missing values (NaN) in each column\n",
    "print(\"\\nOriginal DataFrame duplicates before cleaning:\")\n",
    "print(df.duplicated().sum()) # Count and display the number of duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90779816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Handle Missing Values / Empty Cells ---\n",
    "# For numerical columns ('Calories', 'Pulse', 'Maxpulse'), impute missing values with the median.\n",
    "# The median is preferred over the mean as it's less sensitive to outliers.\n",
    "df['Calories'] = df['Calories'].fillna(df['Calories'].median())\n",
    "df['Pulse'] = df['Pulse'].fillna(df['Pulse'].median())\n",
    "df['Maxpulse'] = df['Maxpulse'].fillna(df['Maxpulse'].median())\n",
    "\n",
    "# For the 'Date' column, drop rows where the date is missing (NaN).\n",
    "# Imputing dates can be complex and may introduce inaccuracies, so dropping is often safer for critical identifiers.\n",
    "df.dropna(subset=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bde94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Handle Inconsistent Date Formats ---\n",
    "# The 'Date' column might contain inconsistencies (e.g., apostrophes, different formats).\n",
    "\n",
    "# First, ensure the 'Date' column is treated as string and remove any trailing apostrophes.\n",
    "df['Date'] = df['Date'].astype(str).str.replace(\"'\", \"\")\n",
    "\n",
    "# Attempt to convert the 'Date' column to datetime objects using a primary format ('%Y/%m/%d').\n",
    "# 'errors='coerce'' will turn any unparseable dates into NaT (Not a Time).\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%Y/%m/%d')\n",
    "\n",
    "# Handle a secondary date format ('%Y%m%d') for dates that failed parsing in the first attempt (are NaT).\n",
    "# This is done by filling the NaT values with new attempts at parsing.\n",
    "df['Date'] = df['Date'].fillna(pd.to_datetime(df['Date'].astype(str), errors='coerce', format='%Y%m%d'))\n",
    "\n",
    "# After attempting multiple formats, drop any rows where the date conversion still failed (i.e., still NaT).\n",
    "df.dropna(subset=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea860b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Handle Duplicate Rows ---\n",
    "# Remove any rows that are exact duplicates of other rows across all columns.\n",
    "# 'inplace=True' modifies the DataFrame directly.\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8caa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Handle Wrong Data ---\n",
    "# This step involves identifying and correcting or removing logically incorrect or out-of-range data.\n",
    "\n",
    "# Check 'Duration' column for unusually high values.\n",
    "# Assuming a workout duration typically doesn't exceed 120 minutes.\n",
    "# Filter out rows where 'Duration' is greater than 120.\n",
    "df = df[df['Duration'] <= 120]\n",
    "\n",
    "# Check 'Pulse' and 'Maxpulse' for unrealistic physiological values.\n",
    "# Assuming 'Pulse' should be between 40 and 220 bpm.\n",
    "# Assuming 'Maxpulse' should be between 80 and 220 bpm.\n",
    "df = df[(df['Pulse'] >= 40) & (df['Pulse'] <= 220)]\n",
    "df = df[(df['Maxpulse'] >= 80) & (df['Maxpulse'] <= 220)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Handle Unnecessary Columns ---\n",
    "# Based on the dataset and common fitness analysis, all columns ('Duration', 'Date', 'Pulse', 'Maxpulse', 'Calories')\n",
    "# are considered relevant for analysis. Therefore, no columns are dropped in this step.\n",
    "# If there were irrelevant columns, you would use: df.drop(columns=['column_name_to_drop'], inplace=True)\n",
    "\n",
    "# --- Final Inspection of the Cleaned DataFrame ---\n",
    "print(\"\\nCleaned DataFrame head:\")\n",
    "print(df.head()) # Display the first 5 rows of the cleaned DataFrame\n",
    "print(\"\\nCleaned DataFrame info:\")\n",
    "print(df.info()) # Display summary info of the cleaned DataFrame (check Dtypes and non-null counts)\n",
    "print(\"\\nCleaned DataFrame missing values (should be 0):\")\n",
    "print(df.isnull().sum()) # Verify no missing values remain\n",
    "print(\"\\nCleaned DataFrame duplicates (should be 0):\")\n",
    "print(df.duplicated().sum()) # Verify no duplicate rows remain\n",
    "\n",
    "print(\"\\n--- Cleaned Dataset ---\")\n",
    "# Display the entire cleaned DataFrame. '.to_string()' prevents truncation for large DataFrames.\n",
    "print(df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
